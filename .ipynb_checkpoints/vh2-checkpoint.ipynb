{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.2.0\n",
      "Keras version: 2.0.8\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Keras version:', keras.__version__)\n",
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "import numpy as np\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max plate length in \"\": 8\n",
      "Max plate length in \"\": 8\n",
      "Letters in train and val do match\n",
      "Letters: 0 1 2 3 4 5 6 7 8 9 A B C E H K M O P T X Y\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def get_counter(directory_path):\n",
    "    dirname = os.path.basename(directory_path)\n",
    "    ann_directory_path = join(directory_path, 'ann')\n",
    "    letters = ''\n",
    "    lens = []\n",
    "    for filename in os.listdir(ann_directory_path):\n",
    "        json_filepath = join(ann_directory_path, filename)\n",
    "        description = json.load(open(json_filepath, 'r'))['description']\n",
    "        lens.append(len(description))\n",
    "        letters += description\n",
    "    print('Max plate length in \"%s\":' % dirname, max(Counter(lens).keys()))\n",
    "    return Counter(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_val = get_counter('./data/val/anpr_ocr/train/')\n",
    "c_train = get_counter('./data/train/anpr_ocr/train/')\n",
    "letters_train = set(c_train.keys())\n",
    "letters_val = set(c_val.keys())\n",
    "if letters_train == letters_val:\n",
    "    print('Letters in train and val do match')\n",
    "else:\n",
    "    raise Exception()\n",
    "# print(len(letters_train), len(letters_val), len(letters_val | letters_train))\n",
    "letters = sorted(list(letters_train))\n",
    "print('Letters:', ' '.join(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max plate length in \"\": 8\n",
      "Max plate length in \"\": 8\n",
      "Letters in train and val do match\n",
      "Letters: 0 1 2 3 4 5 6 7 8 9 A B C E H K M O P T X Y\n"
     ]
    }
   ],
   "source": [
    "c_val = get_counter('./data/val/anpr_ocr/train/')\n",
    "c_train = get_counter('./data/train/anpr_ocr/train/')\n",
    "letters_train = set(c_train.keys())\n",
    "letters_val = set(c_val.keys())\n",
    "if letters_train == letters_val:\n",
    "    print('Letters in train and val do match')\n",
    "else:\n",
    "    raise Exception()\n",
    "# print(len(letters_train), len(letters_val), len(letters_val | letters_train))\n",
    "letters = sorted(list(letters_train))\n",
    "print('Letters:', ' '.join(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    _map = map(lambda x: letters[int(x)], labels)\n",
    "    return ''.join(list(_map))\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "def is_valid_str(s):\n",
    "    for ch in s:\n",
    "        if not ch in letters:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "def is_valid_str(s):\n",
    "    for ch in s:\n",
    "        if not ch in letters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class TextImageGenerator:\n",
    "    \n",
    "    def __init__(self, dirpath, width, height, batch_size, downsample_factor, max_text_len=8):\n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.downsample_factor = downsample_factor\n",
    "        \n",
    "        img_dirpath = join(dirpath, 'img')\n",
    "        ann_dirpath = join(dirpath, 'ann')\n",
    "        self.samples = []\n",
    "        for filename in os.listdir(img_dirpath):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if ext == '.png':\n",
    "                img_filepath = join(img_dirpath, filename)\n",
    "                json_filepath = join(ann_dirpath, name + '.json')\n",
    "                description = json.load(open(json_filepath, 'r'))['description']\n",
    "                if is_valid_str(description):\n",
    "                    self.samples.append([img_filepath, description])\n",
    "        \n",
    "        self.n = len(self.samples)\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        \n",
    "    def build_data(self):\n",
    "        self.imgs = np.zeros((self.n, self.height, self.width))\n",
    "        self.texts = []\n",
    "        for i, (img_filepath, text) in enumerate(self.samples):\n",
    "            img = cv2.imread(img_filepath)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (self.width, self.height))\n",
    "            img = img.astype(np.float32)\n",
    "            img /= 255\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            self.imgs[i, :, :] = img\n",
    "            self.texts.append(text)\n",
    "        \n",
    "    def get_output_size(self):\n",
    "        return len(letters) + 1\n",
    "    \n",
    "    def next_sample(self):\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "    \n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                X_data = np.ones([self.batch_size, 1, self.width, self.height])\n",
    "            else:\n",
    "                X_data = np.ones([self.batch_size, self.width, self.height, 1])\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])\n",
    "            input_length = np.ones((self.batch_size, 1)) * (self.width // self.downsample_factor - 2)\n",
    "            label_length = np.zeros((self.batch_size, 1))\n",
    "            source_str = []\n",
    "                                   \n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.T\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    img = np.expand_dims(img, 0)\n",
    "                else:\n",
    "                    img = np.expand_dims(img, -1)\n",
    "                X_data[i] = img\n",
    "                Y_data[i] = text_to_labels(text)\n",
    "                source_str.append(text)\n",
    "                label_length[i] = len(text)\n",
    "                \n",
    "            inputs = {\n",
    "                'the_input': X_data,\n",
    "                'the_labels': Y_data,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length,\n",
    "                #'source_str': source_str\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tiger = TextImageGenerator('./data/val/anpr_ocr/train/', 128, 64, 8, 4)\n",
    "tiger.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generator output (data which will be fed into the neutral network):\n",
      "1) the_input (image)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f89aba9e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) the_labels (plate number): A024AK54 is encoded as [10, 0, 2, 4, 10, 15, 5, 4]\n",
      "3) input_length (width of image that is fed to the loss function): 30 == 128 / 4 - 2\n",
      "4) label_length (length of plate number): 8\n"
     ]
    }
   ],
   "source": [
    "for inp, out in tiger.next_batch():\n",
    "    print('Text generator output (data which will be fed into the neutral network):')\n",
    "    print('1) the_input (image)')\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        img = inp['the_input'][0, 0, :, :]\n",
    "    else:\n",
    "        img = inp['the_input'][0, :, :, 0]\n",
    "    \n",
    "    plt.imshow(img.T, cmap='gray')\n",
    "    plt.show()\n",
    "    print('2) the_labels (plate number): %s is encoded as %s' % \n",
    "          (labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))))\n",
    "    print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' % \n",
    "          (inp['input_length'][0], tiger.width))\n",
    "    print('4) label_length (length of plate number): %d' % inp['label_length'][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def train(width, load=False):\n",
    "    # Input Parameters\n",
    "    height = 64\n",
    "\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, width, height)\n",
    "    else:\n",
    "        input_shape = (width, height, 1)\n",
    "        \n",
    "    batch_size = 32\n",
    "    downsample_factor = pool_size ** 2\n",
    "    tiger_train = TextImageGenerator('./data/train/anpr_ocr/train/', width, height, batch_size, downsample_factor)\n",
    "    tiger_train.build_data()\n",
    "    tiger_val = TextImageGenerator('./data/val/anpr_ocr/train/', width, height, batch_size, downsample_factor)\n",
    "    tiger_val.build_data()\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (width // (pool_size ** 2), (height // (pool_size ** 2)) * conv_filters)\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirecitonal GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[tiger_train.max_text_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    if load:\n",
    "        model = load_model('./tmp_model.h5', compile=False)\n",
    "    else:\n",
    "        model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    \n",
    "    if not load:\n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "        test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "        model.fit_generator(generator=tiger_train.next_batch(), \n",
    "                            steps_per_epoch=tiger_train.n,\n",
    "                            epochs=1, \n",
    "                            validation_data=tiger_val.next_batch(), \n",
    "                            validation_steps=tiger_val.n)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "the_input (InputLayer)           (None, 128, 64, 1)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 128, 64, 16)   160         the_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)              (None, 64, 32, 16)    0           conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                   (None, 64, 32, 16)    2320        max1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)              (None, 32, 16, 16)    0           conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "reshape (Reshape)                (None, 32, 256)       0           max2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dense1 (Dense)                   (None, 32, 32)        8224        reshape[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru1 (GRU)                       (None, 32, 512)       837120      dense1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "gru1_b (GRU)                     (None, 32, 512)       837120      dense1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 32, 512)       0           gru1[0][0]                       \n",
      "                                                                   gru1_b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "gru2 (GRU)                       (None, 32, 512)       1574400     add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru2_b (GRU)                     (None, 32, 512)       1574400     add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 32, 1024)      0           gru2[0][0]                       \n",
      "                                                                   gru2_b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense2 (Dense)                   (None, 32, 23)        23575       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "softmax (Activation)             (None, 32, 23)        0           dense2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 4,857,319\n",
      "Trainable params: 4,857,319\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/1\n",
      "   69/10281 [..............................] - ETA: 7672s - loss: 27.6435"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-308b3208bb84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-9cac08af4697>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(width, load)\u001b[0m\n\u001b[0;32m     87\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtiger_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                             validation_steps=tiger_val.n)\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2042\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2044\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1762\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1763\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(128, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
